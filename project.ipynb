{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chrysanthos Lianos\n",
    "#### MSc Data Science 2016 Part Time\n",
    "#### Machine Learning and Computational statistics Project\n",
    "\n",
    "### First Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as image\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getdf(type):\n",
    "    tables = []\n",
    "    for i in range(10):\n",
    "        temp_df = pd.read_csv('D:/mnistdata/{}{}.txt'.format(str(type),i),sep = ' ', names = range(784))\n",
    "        if str(type) == 'train':\n",
    "            temp_df['target'] = i\n",
    "        tables.append(temp_df)\n",
    "    tables = pd.concat(tables)\n",
    "    return tables\n",
    "\n",
    "#testset,trainset = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the data\n",
    "train_X is the set of training data, test_X is test\n",
    "train_Y is the OneHot column for train_X and also has column which is aggregation of values eg 0: 100000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = getdf('train')\n",
    "test_X = getdf('test')\n",
    "# create train_y \n",
    "enc = OneHotEncoder(dtype='int') # create int type to concatenate later\n",
    "train_Y = pd.DataFrame(enc.fit_transform(train_X['target'].reshape(-1,1)).toarray()) #training for Y\n",
    "train_Y['aggr'] = train_Y.apply(lambda row: ''.join(map(str, row)), axis=1)\n",
    "# in order to access eg the first row of the train_X use .iloc[0]\n",
    "# to see all rows whose target is in range (0..9) use train_X.loc[trainX['target'] == 0]\n",
    "#train_X.loc[train_X['target']== 0].sample(5)\n",
    "#len(train_X.loc[train_X['target']== 1])\n",
    "# X is train_X.ix[:,:784] and Y is train_X['target']\n",
    "X = train_X.ix[:,:784]\n",
    "# add 1 infront of X\n",
    "X.insert(0,'ones',1)\n",
    "t = train_X['target']\n",
    "N,D = X.shape\n",
    "#set params\n",
    "winit = np.zeros(D)\n",
    "l = 1.0\n",
    "options = [500,1/1000000 ,8/N]  # accuracy of 6 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Cost function: 267223.9979001588\n",
      "Iteration: 1, Cost function: 267223.9979001588\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    yx = 1.0/(1+np.exp(-z))\n",
    "    return yx\n",
    "\n",
    "def ml_logregTrain(t,X,l,winit,options):\n",
    "    w = winit\n",
    "    iterations = options[0]\n",
    "    tol = options[1]\n",
    "    eta = options[2]\n",
    "    ewold = float('-inf')\n",
    "    for it in range(0,iterations):\n",
    "        yx = np.dot(X,w)\n",
    "        s = sigmoid(yx)\n",
    "        ew = sum(np.multiply(t,s)) - np.log(sum(np.exp(s)))\n",
    "        #ew = sum(np.multiply(t,np.log(s)) + np.multiply((1-t),np.log(1-s))) - np.dot((0.5 * l), np.dot(w.transpose(),w))  \n",
    "        print('Iteration: {}, Cost function: {}'.format(it,ew,ewold))\n",
    "        if np.absolute(ew -ewold) < tol:\n",
    "            break\n",
    "        gradient = np.dot((t-s).transpose(),X) - np.multiply(l,w)\n",
    "        #gradient = np.dot(X.transpose(),(t-s)) - np.multiply(l,w)\n",
    "        w += np.multiply(np.float(eta),gradient)\n",
    "        ewold=ew\n",
    "    ew =0\n",
    "    return w \n",
    "\n",
    "\n",
    "#w = ml_logregTrain(train_Y['aggr'], X, l, winit, options)\n",
    "w = ml_logregTrain(train_X['target'],X,l,winit,options)\n",
    "#w = ml_logregTrain(t,X,l,winit,options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y2 = pd.DataFrame(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Y2[:].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y2['period'] = Y2.iloc[:,0:9].apply(lambda x: ''.join(str(x)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X2 = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_Y2 = np.concatenate(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
